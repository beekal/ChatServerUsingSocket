{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF 2.0 -  Basics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOf5IX5i9pamyqCmHxH6Jr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beekal/ChatServerUsingSocket/blob/master/0%20Basics%20-%20TF/4.0_TF_2.0_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlTyY3IsvEdO",
        "colab_type": "text"
      },
      "source": [
        "# TF 2.0 Topics Covered\n",
        "1. TF.Data : A single point of entry to handle any/ varied data type ranging from pandas, csv, image, text, TfRecordByte e.t.c\n",
        "2. TFX: Tensorflow extended,  which aims to  provided end to end TF ecosystem from its  research/ prototype to  the server deployment. It includes the following  all of  which we will cover in this notebook\n",
        "  -  TF validation : Used to validate the data\n",
        "  -  TF Transform : Used to transform the data to its modeling state\n",
        "  -  TF Modeling / Analysis : Used to create the model and evaluate its performance. Reiterate until satisfactory Metric reached.\n",
        "  - TF Serving: Used to serve the model to production with versioning/ Rollback capabilities.\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YO0K90gu610",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "28d8b3cb-ed00-4b6f-f5da-82c74f863b7d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy\n",
        "\n",
        "print(f'TF version : ', tf.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version :  2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fyqkv1Vt0B7x",
        "colab_type": "text"
      },
      "source": [
        "## TF.Data\n",
        "Depending on the data source you wil have to use different TF data load calls\n",
        "  - Data in memory :\n",
        "      - tf.data.Dataset.from_tensors() or\n",
        "      - tf.data.Dataset.from_tensor_slices()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMSgOjW3zexi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dfdb8990-ceee-4d0c-9594-8cfc3c67c1fa"
      },
      "source": [
        "d_mem = tf.data.Dataset.from_tensor_slices([1,2])\n",
        "print(f' Tf.Data from memory : ' ,[e.numpy() for e in d_mem])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Tf.Data from memory :  [1, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybu8cCrS5IN8",
        "colab_type": "text"
      },
      "source": [
        "## TF Transform :\n",
        "We can apply different type of transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoPnPgkk1XaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}